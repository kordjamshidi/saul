
The `SL_model` package aims at providing the possibility of designing structured output prediction models, based on generalized linear models such as structured SVMs and structured Perceptrons.
For implementating any structured learning problem in SL, we need to implement the following classes, [see here.](http://cogcomp.cs.illinois.edu/software/illinois-sl/)
<ul>
<li>The input structure, x. This should implement the IInstance interface.</li>

<li>The output structure, y. This should implement the IStructure interface.</li>

<li>A procedure to compute the feature vector Φ(x,y). For this you need to extend the AbstractFeatureGenerator class and override its getFeatureVector method.</li>

<li>A procedure InferenceSolver to perform the loss-augmented inference,

argmaxy′wTΦ(x,y′)+Δ(y,y′)

For this you need to extend the AbstractInferenceSolver class.</li>

<li>At test time, we need to solve

argmaxy′wTΦ(x,y′)
We will call this the MAP inference problem. For this we can just set Δ(y,y′) to zero in the loss-augmented inference solver.</li>

</ul>

Now here in Saul-SL, what we do is that the way we define our model is based on Saul's conceptual abstraction rather than the SL abstraction. In other words Saul user writes the program in terms of Classifiers and Constraints and the above mentioned modules are provided by Saul.
-The input structure is the collection of the input components of each individual classifier.

-The output structure is the collection of the labels

-The feature vector is the concatenation of the vectors generated by (input-feature * output-label) for each individual classifier and a global join feature function is built automatically based on those join features of the independent classifiers.

-The inference is done using the constraints that express the correlations between the Classifiers.

This model implements the idea of collective classification in the framework of structured output prediction models and provides the possibility of using global first order constraints and domain knowledge easily in the structured learning model.

The underlying inference is performed using ILP techniques.

###The ER example

The explanation of the ER problem can be found in the [EntityRelation example](/saul-examples/src/main/scala/edu/illinois/cs/cogcomp/saulexamples/nlp/EntityRelation/README.md).
To solve this problem and extract the relations and entities jointly using SL's structured output prediction models, we use the same problem specification of this problem that is used for other configurations in Saul. This specification includes defining the
[ER data model](/saul-examples/src/main/scala/edu/illinois/cs/cogcomp/saulexamples/nlp/EntityRelation/EntityRelationDataModel.scala),
 [classifiers](/saul-examples/src/main/scala/edu/illinois/cs/cogcomp/saulexamples/nlp/EntityRelation/EntityRelationClassifiers.scala) and [constraints](/saul-examples/src/main/scala/edu/illinois/cs/cogcomp/saulexamples/nlp/EntityRelation/EntityRelationConstraints.scala).
 The only different part is the end ER application is to simply call `StructuredLearning("NodeType_Name", "ListOfConstrainedClassifiers_Name")`, where `NodeTyeName` is a node type in our dataModel and indicates the type of examples that our model receives.
 In fact, this specifies the type of most global object that is used as an independent example. The evaluation of the model also is done by calling def `Evaluate("NodeType_Name", "ListOfConstrainedClassifiers_Name",myModelName, modelPath)`. This is the
 [end ER application](/saul-examples/src/main/scala/edu/illinois/cs/cogcomp/saulexamples/nlp/EntityRelation/EntityRelationApp_SL.scala) that uses SL to train and test.

###Saul-SL provided components for developer's information

 <ul>
 <li> A __Saul IInstance__ (`Saul_SL_Instance`),  is simply a node in the data model graph. We call is a head because it is a global object and will be the head of a potential inference module later. Normally, we will have a classifier that applies on the head node and also other local classifiers that are applied on other nodes which are connected to the head node. </li>
 <li> A __Saul Structure__ (`Saul_SL_Label_Structure`), is simply a list of labels collected fro the labels of all the engaged classifiers in the structured model. </li>
 <li> __Feature Generation__ (`SL_FeatureGenerator`), The global feature function is made by adding up (and concatenation) of the join feature functions of all involved classifiers. The SparseNetwork structure is used for keeping the information of the classifiers and the LTU keeping the vectors of weights.
 <li> __Saul Inference__ (`Saul_SL_Inference`), simply receives the list of constrained classifiers, one of these is a classifier which applies on the head object and the others are parts of the objective function and all of these share a set of constraints. Hence, inference is easily done by calling LBJava on the list of constrained classifiers.   </li>
 <li> __Saul Loss__ this is simply the normalized aggregation (average) of the hamming loss of the classifiers assigned labels, this is by default equally weighted but can be extended to input weights. </li>
 <li> __Loss augmented Inference__ the score of each classifier is augmented by its loss, before the inference is performed in LBJava. This is done by using a method (that we have added) in LBJava's Learner, called `scoresAugmented`. For this modified score to be returned we set a flag called lossFlag before calling inference and after inference this flag is unset.
</ul>






